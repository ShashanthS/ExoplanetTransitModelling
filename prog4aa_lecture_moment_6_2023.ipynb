{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Programming for A&A\n",
    "\n",
    "### Lecture moment 6: Scipy and selecting data from arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scipy\n",
    "Scipy is a collection of packages based on numpy, which enable numerical calculations, statistical data analysis and signal processing amongst other things. \n",
    "\n",
    "Here we will focus on using Scipy's `optimize` to fit models to data. Along the way we will also learn more about using conditional statements to select data from arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will import the packages we need:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# We need to load each scipy package individually (a package is a collection of functions):\n",
    "import scipy.optimize as spopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The bolometric luminosity functions of quasars\n",
    "We're going to take a look at the data in the text file `quasar_bol_lumfunc.dat`, which gives the observed _bolometric luminosity functions_ of quasars (rapidly-accreting supermassive black holes) for different redshifts. \n",
    "* _Bolometric_ means the total luminosity (in solar luminosities)\n",
    "* A _luminosity function_ is a histogram of the number of objects per unit volume and luminosity. \n",
    "\n",
    "First let's take a look at the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quasar_bol_lumfunc.dat', 'r') as f: \n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading in the data\n",
    "We'll now read in the data we need, which is just the first four columns. Since column names are not given, the data are read into a 2-D array. For convenience we will then assign each column to a separate 1-D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsr_lumfun = np.genfromtxt('quasar_bol_lumfunc.dat',comments=';',usecols=[0,1,2,3])\n",
    "print(qsr_lumfun)\n",
    "z, loglum_sol, lf, lf_err = qsr_lumfun[:,0], qsr_lumfun[:,1], qsr_lumfun[:,2], qsr_lumfun[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selecting on redshift and plotting\n",
    "* We can use conditional statements to select data with certain properties, e.g. the redshift `z`. \n",
    "* Plotting the data for given redshifts, we see that some data have much larger errors than others. We can remove these data with a conditional statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,7])\n",
    "err_lim = 0.2  # Choose maximum error bar size allowed\n",
    "for zval in [0.5, 1.0, 2.0]:\n",
    "    # Note that if we want to combine different conditions we need to put them in parentheses:\n",
    "    plt.errorbar(loglum_sol[(z==zval) & (lf_err < err_lim)], lf[(z==zval) & (lf_err < err_lim)], \n",
    "                 yerr=lf_err[(z==zval) & (lf_err < err_lim)], label='z = '+str(zval), linestyle='')\n",
    "plt.xlabel(r'$\\log(L_{\\rm bol}/L_{\\odot})$',fontsize=14)\n",
    "plt.ylabel(r'${\\rm d}\\log \\phi/{\\rm d}\\log(L_{\\rm bol})$ (Mpc$^{-3}$ $\\log(L_{\\rm bol})^{-1})$',fontsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining a model to fit the data\n",
    "* The data look like they might be fitted by a straight lines with a change in gradient at a 'break'. Let's define a function for this model, so we can fit it...\n",
    "* Note that the ordering of function parameters is set by the `curve_fit` function we will use to fit it ([check the documentation for curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)): \n",
    "    * The data x-values go first, then the function parameters. The function only outputs the model y-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkn_lin(xvals,grad1,grad2,bk,y_bk):\n",
    "    '''Linear model with a break:\n",
    "        Inputs: xvals: x-values, grad1/grad2 gradient below/above break, bk: x-value for break\n",
    "        y_bk: y-value at break (sets the model normalisation)\n",
    "        Returns: mod_yvals: model y-values for given x-values and parameters'''\n",
    "    \n",
    "    mod_yvals = np.zeros(len(xvals)) # We will not define and fill array in one step, so need to define it first\n",
    "\n",
    "    # Choose linear model based on whether x-value below/above break \n",
    "    # The condition sets the gradient we use. The intercept at the break is the same in both cases.\n",
    "    mod_yvals[xvals < bk] = grad1*(xvals[xvals < bk]-bk) + y_bk\n",
    "    mod_yvals[xvals >= bk] = grad2*(xvals[xvals >= bk]-bk) + y_bk\n",
    "    return mod_yvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Check the model\n",
    "* Before fitting the model you should always plot it to check that it works and seems suitable to describe the data!\n",
    "* We can also use a visual comparison to choose some plausible starting parameters for the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zval, err_lim = 2.0, 0.2  # Choose the redshift and error values to select the data to compare with the model\n",
    "x_model = np.linspace(10,16,100) # The model is continuous so we should not just use the data values to plot\n",
    "                                 # or it will look 'wrong'. So we define a grid of x-values to evaluate it on\n",
    "\n",
    "plt.figure(figsize=[10,7])\n",
    "plt.errorbar(loglum_sol[(z==zval) & (lf_err < err_lim)], lf[(z==zval) & (lf_err < err_lim)], \n",
    "                 yerr=lf_err[(z==zval) & (lf_err < err_lim)], label='z = '+str(zval), linestyle='')\n",
    "plt.plot(x_model,bkn_lin(x_model,-1,-2,13,-5),label='model')    \n",
    "plt.xlabel(r'$\\log(L_{\\rm bol}/L_{\\odot})$',fontsize=14)\n",
    "plt.ylabel(r'${\\rm d}\\log \\phi/{\\rm d}\\log(L_{\\rm bol})$ Mpc$^{-3}$ $\\log(L_{\\rm bol})^{-1}$',fontsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting the model\n",
    "* We use `scipy.optimize.curve_fit` to fit the data including its errors (these 'weight' the fit: see the Statistical Methods course for more details!)\n",
    "* The function needs a 'guess' for its starting parameters, which we give as the list p0. Your guess needs to be good enough that the fitting function can find the best fit. It does this by trying to minimise the _chi-squared_ : the total squared difference of the y-values of the data and model (weighted by errors).\n",
    "* If you choose starting parameters that are far from the best-fitting ones, the function may not find the best-fit (it may get stuck in a local minimum of chi-squared). Smooth model functions are more forgiving than those with sharp edges/features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience we will pre-select our data into 1-D arrays:\n",
    "zval, err_lim = 1.0, 0.2\n",
    "xdata, ydata, yerr = loglum_sol[(z==zval) & (lf_err < err_lim)], lf[(z==zval) & (lf_err < err_lim)],\\\n",
    "                            lf_err[(z==zval) & (lf_err < err_lim)]\n",
    "# Our earlier plotted model was not too bad, so we will use it for the starting parameters\n",
    "p0 = [-1,-2,13,-5]\n",
    "params, params_covariance = spopt.curve_fit(bkn_lin, xdata, ydata, p0, sigma=yerr)\n",
    "# The function outputs two arrays with the best-fitting parameters and the covariance matrix, which give an estimate\n",
    "# of the errors on the parameters (and the correlated errors between them). The square-root of the diagonal values \n",
    "# of the covariance matrix array corresponds to 'traditional' 1-sigma error bars. \n",
    "print(\"Best-fitting parameters, errors = \",params, np.sqrt(np.diag(params_covariance)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot the data and best-fitting model\n",
    "Finally plot the best-fitting model and the data to check that the fit looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,7])\n",
    "plt.errorbar(xdata,ydata,yerr=yerr,label='z = '+str(zval), linestyle='')\n",
    "# Note a handy trick: in a function call you can 'unpack' a list into separate parameters, to fit the\n",
    "# required function definition, using the * prefix:\n",
    "plt.plot(x_model,bkn_lin(x_model,*params),label='model')    \n",
    "plt.xlabel(r'$\\log(L_{\\rm bol}/L_{\\odot})$',fontsize=14)\n",
    "plt.ylabel(r'${\\rm d}\\log \\phi/{\\rm d}\\log(L_{\\rm bol})$ Mpc$^{-3}$ $\\log(L_{\\rm bol})^{-1}$',fontsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
